{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction, transformation, and loading into a JSON file\n",
    "This is part of the project described in <https://github.com/amchagas/OSH_papers_DB>, check the project readme for more details.\n",
    "\n",
    "This notebook loads data sources and merges them in a single compressed JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rispy\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from project_definitions import baseDir, dataSourceDir, dataOutDir, figDir, articleDataFile\n",
    "from project_definitions import store_data, load_data\n",
    "from pprint import pprint\n",
    "import html\n",
    "from urllib.parse import unquote\n",
    "from jellyfish import damerau_levenshtein_distance as edit_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scieloSource = {\n",
    "    'paths': [dataSourceDir / x for x in (\"scielo.ris\",)],\n",
    "    'rispy_args': {},\n",
    "    'col_rename': {},\n",
    "    'transforms': [],\n",
    "}\n",
    "scopusSource = {\n",
    "    'paths': [dataSourceDir / x for x in (\"scopus.ris\",)],\n",
    "    'rispy_args': {},\n",
    "    'col_rename': {},\n",
    "    'transforms': [],\n",
    "}\n",
    "wosSource = {\n",
    "    'paths': [dataSourceDir / x for x in (\"wos1-500.ciw\", \"wos501-973.ciw\")],\n",
    "    'rispy_args': {'implementation': 'wok'},\n",
    "    'col_rename': {'publication_year': 'year', 'document_title': 'title'},\n",
    "    'transforms': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_source(dataSource):\n",
    "    dfs = []\n",
    "    for path in dataSource['paths']:\n",
    "        with path.open() as f:\n",
    "            df = pd.DataFrame(rispy.load(f, **dataSource['rispy_args']))\n",
    "        df['__source'] = [[path.name] for _ in range(len(df))]\n",
    "        dfs.append(df)\n",
    "    cdf = pd.concat(dfs, join='outer', ignore_index=True)\n",
    "    cdf = cdf.rename(columns=dataSource['col_rename'])\n",
    "    for trans in dataSource['transforms']:\n",
    "        cdf = cdf.transform(trans)\n",
    "    return cdf.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "scieloData = load_source(scieloSource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "scopusData = load_source(scopusSource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "wosData = load_source(wosSource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDataList = [scieloData, scopusData, wosData]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = pd.concat(allDataList, join='outer', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_series_keep_longest(sx):\n",
    "    if sx.isna().all():\n",
    "        return np.nan\n",
    "    if sx.name == '__source':\n",
    "        return sx.sum()\n",
    "    return sx[sx.map(len, na_action='ignore').idxmax()]\n",
    "\n",
    "def merge_records_keep_longest(dfx):\n",
    "    return dfx.agg(merge_series_keep_longest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only article data\n",
    "article_data = allData.loc[allData[\"type_of_reference\"].eq('JOUR') | allData[\"publication_type\"].eq('J')]\n",
    "# Merge data with same DOI\n",
    "article_doi = article_data.groupby(article_data['doi'].values).agg(merge_records_keep_longest)\n",
    "# Reassemble data with and without DOI\n",
    "article_nodoi = article_data[~article_data.doi.isin(article_doi.index)]\n",
    "article_data = pd.concat([article_doi, article_nodoi], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_titles(sx):\n",
    "    return (\n",
    "        sx\n",
    "        .str.lower()\n",
    "        .str.replace(r'[^\\s\\w]', ' ', regex=True)\n",
    "        .str.replace(r'\\s+', ' ', regex=True)\n",
    "        .str.strip()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Match:\n",
    "    \"\"\"\n",
    "    Index string values with similar strings under the same index, for use in a `groupby`.\n",
    "\n",
    "    First normalizes titles. Then, for each value, returns the index of the first previously indexed value\n",
    "    whose edit_distance is <= threshold, or a new index if none is found.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, threshold=0):\n",
    "        self.df = df\n",
    "        assert not df['title'].hasnans\n",
    "        self.titles = clean_titles(self.df['title'])\n",
    "        self.threshold = threshold\n",
    "        self.match_index = {}\n",
    "    def match(self, x):\n",
    "        x = self.titles.loc[x]\n",
    "        if x in self.match_index:\n",
    "            return self.match_index[x]\n",
    "        if self.threshold > 0:\n",
    "            for m, idx in self.match_index.items():\n",
    "                if edit_distance(x, m) <= self.threshold:\n",
    "                    self.match_index[x] = idx\n",
    "                    return self.match_index[x]\n",
    "        self.match_index[x] = len(self.match_index)\n",
    "        return self.match_index[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_g = article_data.groupby(Match(article_data, 5).match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = articles_g.agg(list)[articles_g.size()>=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test alternatives matchers\n",
    "# articles_gx = article_data.groupby(Match(article_data, 15).match)\n",
    "# bb = articles_gx.agg(list)[articles_gx.size()>=2]\n",
    "# set(clean_titles(aa.explode('title')['title'])).difference(clean_title(bb.explode('title')['title']))\n",
    "# set(clean_titles(bb.explode('title')['title'])).difference(clean_title(aa.explode('title')['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that matching titles also have matching year and author (impl: first author last name)\n",
    "assert aa['year'].map(lambda x: len(set(x)) < 2).all()\n",
    "aa['authors'].map(\n",
    "    lambda x: set(\n",
    "        tuple(z.split(',')[0].split(' ')[-1] for z in y) # last name of each author\n",
    "        for y in x\n",
    "        if not ( isinstance(y, np.float) and pd.isna(y) ) # skip NANs\n",
    "    )\n",
    ").map(\n",
    "    lambda x: sum(\n",
    "        edit_distance(y, z) # sum the edit distances\n",
    "        for x in list(zip(*x))[:1] # first authors\n",
    "        for i, y in enumerate(x) for z in x[i+1:] # distinct pairs\n",
    "    )\n",
    ").max() < 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>623</td>\n",
       "      <td>706</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>623</td>\n",
       "      <td>706</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>10.1016/j.ohx.2020.e00127</td>\n",
       "      <td>Research on Monitoring Platform of Agricultura...</td>\n",
       "      <td>[Pearce, J.M.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              doi  \\\n",
       "count                         623   \n",
       "unique                        623   \n",
       "top     10.1016/j.ohx.2020.e00127   \n",
       "freq                            1   \n",
       "\n",
       "                                                    title         authors  \n",
       "count                                                 706             702  \n",
       "unique                                                706             680  \n",
       "top     Research on Monitoring Platform of Agricultura...  [Pearce, J.M.]  \n",
       "freq                                                    1              10  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_data[['doi', 'title', 'authors']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "article_data = articles_g.agg(merge_records_keep_longest)\n",
    "article_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store deduplicated data and check the stored version reproduces the data\n",
    "store_data(article_data, articleDataFile)\n",
    "assert article_data.equals(load_data(articleDataFile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load article data (instead of running the code above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corrections = {\n",
    "    'doi': {\n",
    "        r'^(.*)/pdf$': r'\\1',\n",
    "#        r'^(.*)/\\w+/$': r'\\1',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data = load_data(articleDataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">doi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>10.1088/2058-7058/31/8/34/pdf</td>\n",
       "      <td>10.1088/2058-7058/31/8/34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               doi                           \n",
       "                              self                      other\n",
       "245  10.1088/2058-7058/31/8/34/pdf  10.1088/2058-7058/31/8/34"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_article_data = article_data.replace(data_corrections, regex=True)\n",
    "article_data.compare(rep_article_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data = rep_article_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLOS Collection sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "plosData = pd.read_csv('https://raw.githubusercontent.com/amchagas/open-source-toolkit/main/plos-items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_article = plosData[\n",
    "    \"Content Type (URL items only - Research Article, Web Article, Commentary, Video, Poster)\"\n",
    "].eq(\"Research Article\")\n",
    "sel_hardware = plosData[\"Hardware or software\"].eq(\"hardware\")\n",
    "plosData = plosData.loc[sel_article & sel_hardware]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert plosData[\"URI (DOI or URL)\"].notna().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the doi and doi-like, fixing doi-like containing extra stuff\n",
    "re_doi = r\"(10\\.[1-9]\\d{3,}(?:\\.\\d+)*/.+)\"\n",
    "re_http_doi_fix = r\"https?://.*/\" + re_doi + r\"(?:/|/full|/abstract|#\\w+)$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "plosData_doi = plosData['URI (DOI or URL)'].str.extract(re_doi)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "plosData_doi_http_doi_fixed = (\n",
    "    plosData['URI (DOI or URL)']\n",
    "    .str.extract(re_httpdoi)[0]\n",
    "    .map(unquote, na_action='ignore')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10.5334/joh.7/</td>\n",
       "      <td>10.5334/joh.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10.5334/joh.4/</td>\n",
       "      <td>10.5334/joh.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>10.3389/fnbeh.2019.00140/full</td>\n",
       "      <td>10.3389/fnbeh.2019.00140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>10.3389/fncir.2012.00098/full</td>\n",
       "      <td>10.3389/fncir.2012.00098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10.3389/fneng.2014.00043/full</td>\n",
       "      <td>10.3389/fneng.2014.00043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>10.3389/fnins.2019.00784/full</td>\n",
       "      <td>10.3389/fnins.2019.00784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>10.1088/1741-2552/aa6806#jneaa6806f01</td>\n",
       "      <td>10.1088/1741-2552/aa6806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>10.5334/joh.14/</td>\n",
       "      <td>10.5334/joh.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>10.3389/fphys.2019.00099/abstract</td>\n",
       "      <td>10.3389/fphys.2019.00099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      self                     other\n",
       "35                          10.5334/joh.7/             10.5334/joh.7\n",
       "36                          10.5334/joh.4/             10.5334/joh.4\n",
       "96           10.3389/fnbeh.2019.00140/full  10.3389/fnbeh.2019.00140\n",
       "98           10.3389/fncir.2012.00098/full  10.3389/fncir.2012.00098\n",
       "99           10.3389/fneng.2014.00043/full  10.3389/fneng.2014.00043\n",
       "103          10.3389/fnins.2019.00784/full  10.3389/fnins.2019.00784\n",
       "126  10.1088/1741-2552/aa6806#jneaa6806f01  10.1088/1741-2552/aa6806\n",
       "128                        10.5334/joh.14/            10.5334/joh.14\n",
       "134      10.3389/fphys.2019.00099/abstract  10.3389/fphys.2019.00099"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plosData_doi.loc[plosData_doi_http_doi_fixed.notna()].compare(plosData_doi_http_doi_fixed.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'doi' not in plosData\n",
    "plosData['doi'] = plosData_doi_http_doi_fixed.where(plosData_doi_http_doi_fixed.notna(), plosData_doi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4              10.1002/elps.201800304\n",
       "35                      10.5334/joh.7\n",
       "36                      10.5334/joh.4\n",
       "65       10.1021/acs.analchem.9b02628\n",
       "66                  10.1063/1.4941068\n",
       "                    ...              \n",
       "251      10.1371/journal.pone.0011890\n",
       "317      10.1371/journal.pone.0214460\n",
       "319      10.1371/journal.pone.0192752\n",
       "330    10.1016/j.techfore.2020.119986\n",
       "331                 10.1111/tra.12728\n",
       "Name: doi, Length: 126, dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plosData['doi'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 712\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    len(set(plosData['doi'].dropna()).intersection(article_data['doi'])),\n",
    "    len(set(plosData['doi'].dropna()).symmetric_difference(article_data['doi'])),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "plosData['Title (URL items only)'] = plosData['Title (URL items only)'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many from the collection have their title in article_data\n",
    "plosData['Title (URL items only)'].pipe(clean_titles).map(\n",
    "    lambda x: article_data.title.pipe(clean_titles).str.contains(rf'(?i){x}', regex=True).any()\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many from the collection have their title in article_data if we require they have DOIs\n",
    "plosData['Title (URL items only)'].loc[plosData['doi'].notna()].pipe(clean_titles).map(\n",
    "    lambda x: article_data.loc[article_data['doi'].notna()].title.pipe(clean_titles).str.contains(rf'(?i){x}', regex=True).any()\n",
    ").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219    10.1371/journal.pone.0168207\n",
      "117       10.1016/j.ohx.2017.07.001\n",
      "203    10.1371/journal.pone.0181560\n",
      "231    10.1371/journal.pone.0134989\n",
      "190    10.1371/journal.pone.0201353\n",
      "65     10.1021/acs.analchem.9b02628\n",
      "181    10.1371/journal.pone.0220091\n",
      "232    10.1371/journal.pone.0124938\n",
      "182    10.1371/journal.pone.0228140\n",
      "210    10.1371/journal.pone.0178540\n",
      "Name: doi, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Give me 10 from the collection having DOIs\n",
    "z = plosData['doi'].dropna().sample(10)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219 chaos based simultaneous compression and encryption for hadoop\n",
      "203 feasibility of a 3d printed anthropomorphic patient specific head phantom for patient specific quality assurance of intensity modulated radiotherapy\n",
      "65 odx a fitness tracker based device for continuous bacterial growth monitoring\n",
      "181 a low cost fluorescence reader for in vitro transcription and nucleic acid detection with cas13a\n",
      "232 multi contrast imaging and digital refocusing on a mobile microscope with a domed led array\n",
      "182 fieldwork based determination of design priorities for point of use drinking water quality sensors for use in resource limited environments\n",
      "210 from medical imaging data to 3d printed anatomical models\n"
     ]
    }
   ],
   "source": [
    "# Get their titles if their titles are not in article_data\n",
    "for i, title in plosData.loc[z.index]['Title (URL items only)'].pipe(clean_titles).items():\n",
    "    if not clean_titles(article_data['title']).str.contains(rf'(?i){title}', regex=True).any():\n",
    "        print(i, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selector for DOIs only in the collection\n",
    "sel_new_doi = ~plosData[\"doi\"].dropna().isin(article_data.doi.values)\n",
    "sel_new_doi.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selector for Titles only in the collection\n",
    "sel_new_title = ~clean_titles(plosData[\"Title (URL items only)\"]).isin(clean_titles(article_data['title']))\n",
    "sel_new_title.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottom-illuminated orbital shaker for microalgae cultivation 10.1016/j.ohx.2020.e00143 10.1101/2020.05.01.071878\n"
     ]
    }
   ],
   "source": [
    "# Same title, different DOIs\n",
    "x = plosData[[\"doi\", \"Title (URL items only)\"]].loc[sel_new_doi & ~sel_new_title]\n",
    "for i, y in x[\"Title (URL items only)\"].str.lower().items():\n",
    "    print(\n",
    "        y,\n",
    "        article_data[\"doi\"].loc[\n",
    "            article_data['title'].str.lower().eq(y)\n",
    "        ].squeeze(),\n",
    "        plosData.loc[i, 'doi']\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same DOI, different titles\n",
    "x = plosData.loc[~sel_new_doi & sel_new_title, 'doi']\n",
    "for y in x:\n",
    "    print(\n",
    "        plosData.loc[plosData.doi.eq(y), \"Title (URL items only)\"].squeeze(),\n",
    "        article_data.loc[article_data.doi.eq(y), 'title'].squeeze(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All done, now just mess around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = nad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(article_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dup_title = article_data.duplicated('title', keep=False)\n",
    "dup_doi = article_data.duplicated('doi', keep=False)\n",
    "nan_doi = article_data['doi'].isna()\n",
    "print(\n",
    "    dup_title.sum(),\n",
    "    dup_doi.sum(),\n",
    "    nan_doi.sum(),\n",
    "    (dup_title & dup_doi).sum(),\n",
    "    (dup_title & ~dup_doi).sum(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data.issn.str.replace('[^\\d]', '', regex=True).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data.issn.str.replace('[^\\d]', '', regex=True).value_counts().reset_index().plot(loglog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_data.groupby('year').size().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
