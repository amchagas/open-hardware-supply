{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22e83573-93ef-444d-aaeb-67f07279ea5e",
   "metadata": {},
   "source": [
    "### load derived data (jsonl file) into dictionary\n",
    "This notebook shows how to:\n",
    "- Pull data from the derived data file (JSON lines file)\n",
    "- Extract the information we want, organize it into a dictionary\n",
    "- Save the dictionary into a JSON file\n",
    "\n",
    "After this has been stored into a JSON file, we can load it into pandas, cross check with unpaywall, etc. (all to be done in other notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "863b4be1-a557-4b6f-9454-1f2f418651a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import jsonlines\n",
    "import json\n",
    "import doi as doiLib\n",
    "from unpywall.utils import UnpywallCredentials\n",
    "from unpywall import Unpywall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41dbce4a-015a-4012-8f84-ed860bffb625",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"../data/derived2/\"\n",
    "dataFile = \"records.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39c4dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "#initialData = pd.DataFrame()\n",
    "dataDict = {\"WOSUID\":[],\n",
    "            \"pubTitle\":[],\n",
    "            \"pubYear\":[],\n",
    "            \"pubType\":[],\n",
    "            \"journalTitle\":[],\n",
    "            \"publisher\":[],\n",
    "            \"area\":[],\n",
    "            \"areaCount\":[],\n",
    "            \"identifier\":[],\n",
    "            \"keywords\":[],\n",
    "            \"abstract\":[],\n",
    "            \"doi\":[],\n",
    "            \"validDoi\":[],\n",
    "            \"url\":[],\n",
    "            #\"OA\":[],\n",
    "            #\"OA-pdf_url\":[],\n",
    "            #\"issn\":[],\n",
    "                   }\n",
    "with jsonlines.open(dataPath+dataFile) as reader:   \n",
    "    for obj in reader:\n",
    "        if index<100000:\n",
    "            try:\n",
    "                wosID = obj[\"record\"][\"UID\"][4:]\n",
    "            except KeyError:\n",
    "                wosID = None\n",
    "            dataDict[\"WOSUID\"].append(wosID)\n",
    "            dataDict[\"pubTitle\"].append(obj[\"record\"][\"static_data\"][\"summary\"][\"titles\"][\"title\"][-1][\"content\"])\n",
    "            dataDict[\"pubYear\"].append(obj[\"record\"][\"static_data\"][\"summary\"][\"pub_info\"][\"pubyear\"])\n",
    "            dataDict[\"pubType\"].append(obj[\"record\"][\"static_data\"][\"summary\"][\"doctypes\"][\"doctype\"])\n",
    "            dataDict[\"journalTitle\"].append(obj[\"record\"][\"static_data\"][\"summary\"][\"titles\"][\"title\"][0][\"content\"])\n",
    "               \n",
    "            try:\n",
    "                publisher = obj[\"record\"][\"static_data\"][\"summary\"][\"publishers\"][\"publisher\"][\"names\"][\"name\"][\"unified_name\"]\n",
    "            except KeyError:\n",
    "                publisher = None\n",
    "                \n",
    "            dataDict[\"publisher\"].append(publisher)\n",
    "            try:\n",
    "                areaCount = obj[\"record\"][\"static_data\"][\"fullrecord_metadata\"][\"category_info\"][\"subheadings\"][\"count\"]\n",
    "                \n",
    "            except KeyError:\n",
    "                areaCount = None\n",
    "            dataDict[\"areaCount\"].append(areaCount)\n",
    "            \n",
    "            try:\n",
    "                area = obj[\"record\"][\"static_data\"][\"fullrecord_metadata\"][\"category_info\"][\"subheadings\"][\"subheading\"]\n",
    "                \n",
    "            except KeyError:\n",
    "                area = None\n",
    "            dataDict[\"area\"].append(area)\n",
    "            \n",
    "            dataDict[\"identifier\"].append(obj[\"record\"][\"dynamic_data\"][\"cluster_related\"][\"identifiers\"][\"identifier\"])\n",
    "            \n",
    "            try:\n",
    "                keyword = obj[\"record\"][\"static_data\"][\"fullrecord_metadata\"][\"keywords\"][\"keyword\"]\n",
    "            except KeyError:\n",
    "                keyword = None\n",
    "            dataDict[\"keywords\"].append(keyword)\n",
    "\n",
    "            try:\n",
    "                abstract = obj[\"record\"][\"static_data\"][\"fullrecord_metadata\"][\"abstracts\"][\"abstract\"][\"abstract_text\"][\"p\"]\n",
    "            except KeyError:\n",
    "                abstract = None\n",
    "            \n",
    "            dataDict[\"abstract\"].append(abstract)\n",
    "            \n",
    "\n",
    "            doi = None\n",
    "            url = None\n",
    "            #print(index)\n",
    "            for item in obj[\"record\"][\"dynamic_data\"][\"cluster_related\"][\"identifiers\"][\"identifier\"]:\n",
    "                try:\n",
    "                    if item[\"type\"]==\"doi\" or item[\"type\"]==\"xref_doi\":    \n",
    "                        doi = item[\"value\"]\n",
    "                except TypeError:\n",
    "                    doi=None\n",
    "                \n",
    "                try:\n",
    "                    validDoi = doiLib.validate_doi(doi)\n",
    "                except ValueError:\n",
    "                    validDoi = None\n",
    "            dataDict[\"doi\"].append(doi)\n",
    "            dataDict[\"validDoi\"].append(validDoi)\n",
    "            \n",
    "            if validDoi !=None:\n",
    "                pass\n",
    "            else:\n",
    "                pass    \n",
    "            try:\n",
    "                url = doiLib.get_real_url_from_doi(doi)\n",
    "            except ValueError:\n",
    "                url=None\n",
    "            dataDict[\"url\"].append(url)           \n",
    "        index=index+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d90efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pulled data\n",
    "import json\n",
    "with open(dataPath+'clean_dictionary.json', 'w') as fp:\n",
    "    json.dump(dataDict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74be9baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#convert dictionary to panda dataframe\n",
    "data = pd.DataFrame.from_dict(dataDict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a33b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"email\") as fid:\n",
    "    unpaywallcred = fid.readline()\n",
    "\n",
    "UnpywallCredentials(\"nick.haupka@gmail.com\")# could not get api cred on time, so using this email which is pasted all over the web.... #unpaywallcred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b90ff93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\unpywall\\cache.py:203: UserWarning: Could not download doi: 10.1145.2556288.2557132\n",
      "  warnings.warn('Could not download doi: {}'.format(doi))\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\unpywall\\cache.py:203: UserWarning: Could not download doi: 10.3233/978-1-61499-393-3-124\n",
      "  warnings.warn('Could not download doi: {}'.format(doi))\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\unpywall\\cache.py:203: UserWarning: Could not download doi: 10.3233/978-1-61499-484-8-631\n",
      "  warnings.warn('Could not download doi: {}'.format(doi))\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\unpywall\\cache.py:203: UserWarning: Could not download doi: 10.18690/18557147.7.2.139-159(2015)\n",
      "  warnings.warn('Could not download doi: {}'.format(doi))\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\unpywall\\cache.py:203: UserWarning: Could not download doi: 10.1504/IJSNET.2016.076858\n",
      "  warnings.warn('Could not download doi: {}'.format(doi))\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\unpywall\\cache.py:203: UserWarning: Could not download doi: 10.13128/Aestimum-20454\n",
      "  warnings.warn('Could not download doi: {}'.format(doi))\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\unpywall\\cache.py:203: UserWarning: Could not download doi: 10.5194/isprsarchives-XL-5-W8-25-2016\n",
      "  warnings.warn('Could not download doi: {}'.format(doi))\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\unpywall\\cache.py:203: UserWarning: Could not download doi: 10.18421/TEM64-02\n",
      "  warnings.warn('Could not download doi: {}'.format(doi))\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\unpywall\\cache.py:203: UserWarning: Could not download doi: 10.4314/jfas.v9i7s.88\n",
      "  warnings.warn('Could not download doi: {}'.format(doi))\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\unpywall\\cache.py:203: UserWarning: Could not download doi: 10.3233/978-1-61499-769-6-293\n",
      "  warnings.warn('Could not download doi: {}'.format(doi))\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\unpywall\\cache.py:203: UserWarning: Could not download doi: 10.19199/2017.2.2038-5625.025\n",
      "  warnings.warn('Could not download doi: {}'.format(doi))\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\unpywall\\cache.py:203: UserWarning: Could not download doi: 10.5277/ABB-01132-2018-02\n",
      "  warnings.warn('Could not download doi: {}'.format(doi))\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\unpywall\\cache.py:203: UserWarning: Could not download doi: 10.6531/JFS.201812_23(2).0005\n",
      "  warnings.warn('Could not download doi: {}'.format(doi))\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\unpywall\\cache.py:203: UserWarning: Could not download doi: 10.25341/D4859D\n",
      "  warnings.warn('Could not download doi: {}'.format(doi))\n",
      "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\unpywall\\cache.py:203: UserWarning: Could not download doi: 10.1504/IJSAMI.2019.101375\n",
      "  warnings.warn('Could not download doi: {}'.format(doi))\n"
     ]
    }
   ],
   "source": [
    "#use unpaywall api to check if papers are open access\n",
    "upArticles = Unpywall.doi(dois=list(data[\"doi\"].dropna()),errors=\"ignore\")             \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "34a03358",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot mask with non-boolean array containing NA / NaN values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ANDREM~1\\AppData\\Local\\Temp/ipykernel_10368/3931677994.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdataMerge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupArticles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'doi'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"outer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataMerge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataMerge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_oa\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataMerge\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#'best_oa_location.license'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3447\u001b[0m         \u001b[1;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3448\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3449\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mis_bool_indexer\u001b[1;34m(key)\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[1;31m# Don't raise on e.g. [\"A\", \"B\", np.nan], see\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                     \u001b[1;31m#  test_loc_getitem_list_of_labels_categoricalindex_with_na\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mna_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot mask with non-boolean array containing NA / NaN values"
     ]
    }
   ],
   "source": [
    "#merge information based on doi\n",
    "##TODO\n",
    "#dataMerge = pd.merge(data, upArticles, on='doi')\n",
    "\n",
    "\n",
    "    \n",
    "#'best_oa_location.license'\n",
    "#df[\"OA\"] = up[\"is_oa\"]\n",
    "#df[\"OA-pdf_url\"] = up[\"best_oa_location.url_for_pdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "957c474f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mleft\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'DataFrame | Series'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mright\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'DataFrame | Series'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mhow\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'inner'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mon\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'IndexLabel | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mleft_on\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'IndexLabel | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mright_on\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'IndexLabel | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mleft_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mright_index\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msuffixes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Suffixes'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'_x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mindicator\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str | None'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Merge DataFrame or named Series objects with a database-style join.\n",
      "\n",
      "A named Series object is treated as a DataFrame with a single named column.\n",
      "\n",
      "The join is done on columns or indexes. If joining columns on\n",
      "columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes\n",
      "on indexes or indexes on a column or columns, the index will be passed on.\n",
      "When performing a cross merge, no column specifications to merge on are\n",
      "allowed.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "left : DataFrame\n",
      "right : DataFrame or named Series\n",
      "    Object to merge with.\n",
      "how : {'left', 'right', 'outer', 'inner', 'cross'}, default 'inner'\n",
      "    Type of merge to be performed.\n",
      "\n",
      "    * left: use only keys from left frame, similar to a SQL left outer join;\n",
      "      preserve key order.\n",
      "    * right: use only keys from right frame, similar to a SQL right outer join;\n",
      "      preserve key order.\n",
      "    * outer: use union of keys from both frames, similar to a SQL full outer\n",
      "      join; sort keys lexicographically.\n",
      "    * inner: use intersection of keys from both frames, similar to a SQL inner\n",
      "      join; preserve the order of the left keys.\n",
      "    * cross: creates the cartesian product from both frames, preserves the order\n",
      "      of the left keys.\n",
      "\n",
      "      .. versionadded:: 1.2.0\n",
      "\n",
      "on : label or list\n",
      "    Column or index level names to join on. These must be found in both\n",
      "    DataFrames. If `on` is None and not merging on indexes then this defaults\n",
      "    to the intersection of the columns in both DataFrames.\n",
      "left_on : label or list, or array-like\n",
      "    Column or index level names to join on in the left DataFrame. Can also\n",
      "    be an array or list of arrays of the length of the left DataFrame.\n",
      "    These arrays are treated as if they are columns.\n",
      "right_on : label or list, or array-like\n",
      "    Column or index level names to join on in the right DataFrame. Can also\n",
      "    be an array or list of arrays of the length of the right DataFrame.\n",
      "    These arrays are treated as if they are columns.\n",
      "left_index : bool, default False\n",
      "    Use the index from the left DataFrame as the join key(s). If it is a\n",
      "    MultiIndex, the number of keys in the other DataFrame (either the index\n",
      "    or a number of columns) must match the number of levels.\n",
      "right_index : bool, default False\n",
      "    Use the index from the right DataFrame as the join key. Same caveats as\n",
      "    left_index.\n",
      "sort : bool, default False\n",
      "    Sort the join keys lexicographically in the result DataFrame. If False,\n",
      "    the order of the join keys depends on the join type (how keyword).\n",
      "suffixes : list-like, default is (\"_x\", \"_y\")\n",
      "    A length-2 sequence where each element is optionally a string\n",
      "    indicating the suffix to add to overlapping column names in\n",
      "    `left` and `right` respectively. Pass a value of `None` instead\n",
      "    of a string to indicate that the column name from `left` or\n",
      "    `right` should be left as-is, with no suffix. At least one of the\n",
      "    values must not be None.\n",
      "copy : bool, default True\n",
      "    If False, avoid copy if possible.\n",
      "indicator : bool or str, default False\n",
      "    If True, adds a column to the output DataFrame called \"_merge\" with\n",
      "    information on the source of each row. The column can be given a different\n",
      "    name by providing a string argument. The column will have a Categorical\n",
      "    type with the value of \"left_only\" for observations whose merge key only\n",
      "    appears in the left DataFrame, \"right_only\" for observations\n",
      "    whose merge key only appears in the right DataFrame, and \"both\"\n",
      "    if the observation's merge key is found in both DataFrames.\n",
      "\n",
      "validate : str, optional\n",
      "    If specified, checks if merge is of specified type.\n",
      "\n",
      "    * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
      "      left and right datasets.\n",
      "    * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
      "      dataset.\n",
      "    * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
      "      dataset.\n",
      "    * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "DataFrame\n",
      "    A DataFrame of the two merged objects.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "merge_ordered : Merge with optional filling/interpolation.\n",
      "merge_asof : Merge on nearest keys.\n",
      "DataFrame.join : Similar method using indices.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Support for specifying index levels as the `on`, `left_on`, and\n",
      "`right_on` parameters was added in version 0.23.0\n",
      "Support for merging named Series objects was added in version 0.24.0\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
      "...                     'value': [1, 2, 3, 5]})\n",
      ">>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
      "...                     'value': [5, 6, 7, 8]})\n",
      ">>> df1\n",
      "    lkey value\n",
      "0   foo      1\n",
      "1   bar      2\n",
      "2   baz      3\n",
      "3   foo      5\n",
      ">>> df2\n",
      "    rkey value\n",
      "0   foo      5\n",
      "1   bar      6\n",
      "2   baz      7\n",
      "3   foo      8\n",
      "\n",
      "Merge df1 and df2 on the lkey and rkey columns. The value columns have\n",
      "the default suffixes, _x and _y, appended.\n",
      "\n",
      ">>> df1.merge(df2, left_on='lkey', right_on='rkey')\n",
      "  lkey  value_x rkey  value_y\n",
      "0  foo        1  foo        5\n",
      "1  foo        1  foo        8\n",
      "2  foo        5  foo        5\n",
      "3  foo        5  foo        8\n",
      "4  bar        2  bar        6\n",
      "5  baz        3  baz        7\n",
      "\n",
      "Merge DataFrames df1 and df2 with specified left and right suffixes\n",
      "appended to any overlapping columns.\n",
      "\n",
      ">>> df1.merge(df2, left_on='lkey', right_on='rkey',\n",
      "...           suffixes=('_left', '_right'))\n",
      "  lkey  value_left rkey  value_right\n",
      "0  foo           1  foo            5\n",
      "1  foo           1  foo            8\n",
      "2  foo           5  foo            5\n",
      "3  foo           5  foo            8\n",
      "4  bar           2  bar            6\n",
      "5  baz           3  baz            7\n",
      "\n",
      "Merge DataFrames df1 and df2, but raise an exception if the DataFrames have\n",
      "any overlapping columns.\n",
      "\n",
      ">>> df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))\n",
      "Traceback (most recent call last):\n",
      "...\n",
      "ValueError: columns overlap but no suffix specified:\n",
      "    Index(['value'], dtype='object')\n",
      "\n",
      ">>> df1 = pd.DataFrame({'a': ['foo', 'bar'], 'b': [1, 2]})\n",
      ">>> df2 = pd.DataFrame({'a': ['foo', 'baz'], 'c': [3, 4]})\n",
      ">>> df1\n",
      "      a  b\n",
      "0   foo  1\n",
      "1   bar  2\n",
      ">>> df2\n",
      "      a  c\n",
      "0   foo  3\n",
      "1   baz  4\n",
      "\n",
      ">>> df1.merge(df2, how='inner', on='a')\n",
      "      a  b  c\n",
      "0   foo  1  3\n",
      "\n",
      ">>> df1.merge(df2, how='left', on='a')\n",
      "      a  b  c\n",
      "0   foo  1  3.0\n",
      "1   bar  2  NaN\n",
      "\n",
      ">>> df1 = pd.DataFrame({'left': ['foo', 'bar']})\n",
      ">>> df2 = pd.DataFrame({'right': [7, 8]})\n",
      ">>> df1\n",
      "    left\n",
      "0   foo\n",
      "1   bar\n",
      ">>> df2\n",
      "    right\n",
      "0   7\n",
      "1   8\n",
      "\n",
      ">>> df1.merge(df2, how='cross')\n",
      "   left  right\n",
      "0   foo      7\n",
      "1   foo      8\n",
      "2   bar      7\n",
      "3   bar      8\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\programdata\\miniconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\n",
      "\u001b[1;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "pd.merge?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e0a48e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ANDREM~1\\AppData\\Local\\Temp/ipykernel_9860/3418008062.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"pubYear\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2004\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2023\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "sns.histplot(data[\"pubYear\"],bins=list(range(2004,2023)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10604348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifier\n",
    "#obj[\"record\"][\"dynamic_data\"][\"cluster_related\"][\"identifiers\"][\"identifier\"]\n",
    "\n",
    "#WOSID \n",
    "#obj[\"record\"][\"UID\"][4:]\n",
    "\n",
    "#'find if this is an article\n",
    "#obj[\"record\"][\"static_data\"][\"summary\"][\"doctypes\"][\"doctype\"]\n",
    "\n",
    "#find publication title\n",
    "#obj[\"record\"][\"static_data\"][\"summary\"][\"titles\"][\"title\"][-1][\"content\"]\n",
    "\n",
    "#find journal title\n",
    "#obj[\"record\"][\"static_data\"][\"summary\"][\"titles\"][\"title\"][0][\"content\"]\n",
    "\n",
    "#find publisher (elsevier, nature, etc)\n",
    "#obj[\"record\"][\"static_data\"][\"summary\"][\"publishers\"][\"publisher\"][\"names\"][\"name\"][\"unified_name\"]\n",
    "\n",
    "#get publication year\n",
    "#obj[\"record\"][\"static_data\"][\"summary\"][\"pub_info\"][\"pubyear\"]\n",
    "\n",
    "#find area (still requires more code to systematically extract all categories)\n",
    "#obj[\"record\"][\"static_data\"][\"fullrecord_metadata\"][\"category_info\"][\"subheadings\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d2bf18",
   "metadata": {},
   "source": [
    "### plot for the paper:\n",
    "- number of papers in OSH over years\n",
    "  - divide them per area (using research areas tags)\n",
    "    - Engineering, life sciences, humanities?\n",
    "- quality of the papers - how many fit the OSHWA OSH classification?\n",
    "- Accessibility of the papers - how many are OA?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
